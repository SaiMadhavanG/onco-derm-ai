{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Card for ResNet-18 on DermaMNIST Image Classification\n",
    "\n",
    "---\n",
    "\n",
    "## Model Details\n",
    "\n",
    "- **Person or Organization Developing Model**:  \n",
    "  This implementation was developed by [Sai Madhavan](https://www.linkedin.com/in/sai-madhavan-g/) and [M Srinivasan](https://www.linkedin.com/in/srinivasan-m-668154228/) as part of a project for AI-839 for skin lesion classification using the DermaMNIST dataset.\n",
    "\n",
    "- **Model Date**:  \n",
    "  November 2024\n",
    "\n",
    "- **Model Version**:  \n",
    "  ResNet-18\n",
    "\n",
    "- **Model Type**:  \n",
    "  Convolutional Neural Network (CNN)\n",
    "\n",
    "- **Information about Training Algorithms, Parameters, Fairness Constraints, or Other Applied Approaches, and Features**:  \n",
    "  ResNet-18 is a deep residual network that introduces skip connections to solve vanishing gradient problems in deep networks. It was trained using the following parameters:  \n",
    "  - Optimizer: Adam  \n",
    "  - Learning Rate: 0.001  \n",
    "  - Batch Size: 32  \n",
    "  - Number of Epochs: 20  \n",
    "  - Loss Function: Cross-Entropy Loss\n",
    "\n",
    "- **Fine Tune**:\n",
    "  We used a pre-trained Resnet-18 model from Pytorch and then fine tuned it for classification purposes on the DermaMNIST dataset.\n",
    "  - Modified the final layers to match the number of classes in the DermaMnist dataset.\n",
    "  - Trained the modified model on the DermaMnist dataset.\n",
    "  - Evaluated the performance of the fine-tuned model.\n",
    "\n",
    "- **Paper or Other Resource for More Information**:  \n",
    "  - [ResNet Original Paper (He et al., 2015)](https://arxiv.org/abs/1512.03385)  \n",
    "  - [DermaMNIST Dataset Resource](https://medmnist.com)\n",
    "\n",
    "- **Citation Details**:  \n",
    "  - ResNet: *He, Kaiming, et al. \"Deep residual learning for image recognition.\" Proceedings of the IEEE conference on computer vision and pattern recognition. 2016.*  \n",
    "  - DermaMNIST: *Yang, Jiancheng, et al. \"MedMNIST Classification Decathlon: A Lightweight AutoML Benchmark for Medical Image Analysis.\" arXiv preprint arXiv:2110.14795 (2021).*\n",
    "\n",
    "- **License**:  \n",
    "  Apache License 2.0 for the ResNet model implementation; refer to the MedMNIST dataset licensing for dataset usage.\n",
    "\n",
    " \n",
    "<!-- /*************  âœ¨ Codeium Command ðŸŒŸ  *************/ -->\n",
    "   Please reach out to [M Srinivasan - (mail id)](mailto:m.srinivasan@iiitb.ac.in) or [Sai Madhavan - (mail id)](mailto:g.saimadhavan@iiitb.ac.in) for any questions or comments about the model.\n",
    "\n",
    "---\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intended Use\n",
    "\n",
    "- **Primary Intended Uses**:  \n",
    "  - Early screening for skin cancer and other serious skin conditions in resource-constrained settings.  \n",
    "  - Assisting non-specialist healthcare workers in making preliminary assessments of skin lesions.  \n",
    "  - Identifying high-risk cases that require referral to dermatology specialists for further evaluation.\n",
    "\n",
    "- **Primary Intended Users**:  \n",
    "  - Non-specialist healthcare workers, such as general practitioners, nurses, and community health workers in rural India.  \n",
    "  - Healthcare providers in underserved regions lacking access to specialized dermatological support.\n",
    "\n",
    "- **Out-of-Scope Use Cases**:  \n",
    "  - Providing a definitive medical diagnosis without specialist consultation.  \n",
    "  - Use in advanced clinical settings where dermatologists and specialized diagnostic tools are available.  \n",
    "  - Screening for skin conditions outside the scope of the model's training (e.g., non-cancerous cosmetic dermatology issues).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Factors\n",
    "\n",
    "- **Relevant Factors**:  \n",
    "  - Demographic and phenotypic groups, including variations in skin tone and lesion types.  \n",
    "  - Environmental conditions like lighting in image capture.\n",
    "\n",
    "- **Evaluation Factors**:  \n",
    "  - Classification accuracy, precision, recall, and F1 score across demographic groups.  \n",
    "  - Sensitivity to image preprocessing and augmentation techniques.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics\n",
    "\n",
    "- **Model Performance Measures**:  \n",
    "  - Accuracy: Overall percentage of correctly classified samples.  \n",
    "  - Precision: Proportion of true positives among predicted positives.  \n",
    "  - Recall (Sensitivity): Proportion of true positives among actual positives.  \n",
    "  - F1 Score: Harmonic mean of precision and recall.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Data\n",
    "\n",
    "- **Datasets**:  \n",
    "  The evaluation was conducted on a subset of the dataset split into training, validation, and test sets. Images were resized to `(224, 224)` and normalized using ImageNet mean (`[0.485, 0.456, 0.406]`) and standard deviation (`[0.229, 0.224, 0.225]`). \n",
    "\n",
    "- **Motivation**:  \n",
    "  The goal of the evaluation data preparation was to ensure consistent preprocessing and transformations for fair model assessment. This included resizing and normalization to align with ResNet-18's pretrained parameters.\n",
    "\n",
    "- **Preprocessing**:  \n",
    "  - Images were normalized by dividing pixel values by 255.  \n",
    "  - Applied a `transforms.Compose` pipeline to perform resizing and normalization.  \n",
    "  - For additional evaluation, data augmentation techniques like horizontal and vertical flips, rotation, and color jitter were applied during testing to assess model robustness.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## Training Data\n",
    "\n",
    "- **Datasets**:  \n",
    "  Training data consisted of the DermaMNIST dataset, augmented to increase diversity and robustness. Images were resized to `(224, 224)` and normalized similarly to the evaluation data.\n",
    "\n",
    "- **Preprocessing**:  \n",
    "  - Images were converted to tensors and resized to `(224, 224)`.  \n",
    "  - Normalization used the ImageNet mean and standard deviation.  \n",
    "  - Data augmentation techniques were extensively applied, including horizontal/vertical flips, random rotations, and color jittering.  \n",
    "  - For each original image, multiple augmented versions were generated and added to the dataset using the provided augmentation function, with unique identifiers for each augmented sample.\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantitative Analyses\n",
    "\n",
    "- **Unitary Results**:  \n",
    "  - Accuracy: 75%  \n",
    "  - Macro F1 Score: 0.539\n",
    "\n",
    "- **Intersectional Results**:  \n",
    "  - Performance variation observed across lesion types, with lower recall for rarer lesion classes.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Ethical Considerations\n",
    "\n",
    "- Potential bias in training data due to overrepresentation of certain demographics or lesion types.  \n",
    "- Model is not a substitute for clinical expertise and should be used only for research purposes.  \n",
    "- Misclassifications could lead to inappropriate confidence in model predictions.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Caveats and Recommendations\n",
    "\n",
    "- The model's performance is dependent on the quality of input images and generalizes poorly to out-of-distribution samples.  \n",
    "- Clinical use requires thorough validation and expert oversight.  \n",
    "- Future work should focus on improving robustness to demographic and environmental variations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
