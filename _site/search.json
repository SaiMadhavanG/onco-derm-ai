[
  {
    "objectID": "todo.html",
    "href": "todo.html",
    "title": "Initialization",
    "section": "",
    "text": "Initialization\n\ncome up with a name\nkedro init\npre commit hooks\n\nlinting\ntesting\nquartodoc\n\ntesting - pytest, git pre commit hook\nauto documentation - quartodoc\n\n\n\nDocumentation\n\nproject card - sai\ndata card\nmodel card\nmlops card\n\n\n\nData Prep\n\nLoad data - kedro\nData versioning - kedro\nImage preprocessing - normalizing, tensorizing and resizing - torchvision - srini\nData augmentation - torchvision\n\nData quality - ?, greater expectation\nright to erasure, forgetting - kedro pipeline\n\n\n\n\nTraining\n\nModel training - Resnet - PyTorch\nModel versioning - mlflow\nModel eval - Sk classification report, k cross val\nhyperparameter tuning - optuna/sklearn search\nautomatic reports - quarto and plotting libs\nModel pruning - pytorch\nadversarial robustness - auto_lirpa\nright to erasure, model retraining - kedro pipeline\n\n\n\nInference\n\nexplainability - deel\nconfidence calibration - deel, ?\nOOD detection - ?\nConformal predictions - deel\n\n\n\nDeployment\n\nmodel containerization - mlflow, docker\nauto model deployment - github actions/cloud provider\ndeployment side eval\ndata drift\nauto retraining triggers\n\n\n\nLLM\n\nllm set up\nllm prompt config\nllm deployment\n\n\n\nFront End\n\nFrontend dashboard - react, bootstrap\nChatbot window"
  },
  {
    "objectID": "reference/normalizing_images.html",
    "href": "reference/normalizing_images.html",
    "title": "normalizing_images",
    "section": "",
    "text": "normalizing_images(data)\nNormalize the pixel values of images in the given DataFrame.\nThis function takes a DataFrame containing image data and normalizes the pixel values by dividing each pixel value by 255.0. The normalized pixel values will be in the range [0, 1].\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npd.DataFrame\nA DataFrame containing image data. The DataFrame must have a column named “image” where each entry is an image represented as a numerical array.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nA DataFrame with the same structure as the input, but with normalized image pixel values."
  },
  {
    "objectID": "reference/normalizing_images.html#parameters",
    "href": "reference/normalizing_images.html#parameters",
    "title": "normalizing_images",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\npd.DataFrame\nA DataFrame containing image data. The DataFrame must have a column named “image” where each entry is an image represented as a numerical array.\nrequired"
  },
  {
    "objectID": "reference/normalizing_images.html#returns",
    "href": "reference/normalizing_images.html#returns",
    "title": "normalizing_images",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npd.DataFrame\nA DataFrame with the same structure as the input, but with normalized image pixel values."
  },
  {
    "objectID": "notebooks/RestNet.html",
    "href": "notebooks/RestNet.html",
    "title": "Fine tune Resnet-18",
    "section": "",
    "text": "This code is for fine-tuning the ResNet model on the DermaMnist dataset.\nThe DermaMnist dataset is a collection of dermatological images used for skin disease classification. Fine-tuning involves taking a pre-trained ResNet model and adapting it to the specific task of classifying images in the DermaMnist dataset.\nThe process typically includes: - Loading the pre-trained ResNet model. - Modifying the final layers to match the number of classes in the DermaMnist dataset. - Training the modified model on the DermaMnist dataset. - Evaluating the performance of the fine-tuned model.\nThis approach leverages the pre-trained features of the ResNet model, which can lead to better performance and faster convergence compared to training a model from scratch.\n\n# import torch\n# import torchvision.models as models\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import models, transforms\n\n# Load the pre-trained ResNet-18 model\nresnet18 = models.resnet18(pretrained=True)\n\n# Print the model architecture\n# print(resnet18.fc)\n\n\nclass DermaMNISTDataset(Dataset):\n    def __init__(self, dataframe, transform=None):\n        self.dataframe = dataframe\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.dataframe)\n\n    def __getitem__(self, idx):\n        image = self.dataframe[\"image\"][idx]  # (28, 28, 3) numpy array\n        # image = (image * 255).astype(np.uint8)  # Convert to uint8 for transforms\n        label = self.dataframe[\"label\"][idx]\n\n        # Convert numpy image to PIL Image for applying transforms\n        image = transforms.ToPILImage()(image)\n        image = transforms.ToTensor()(image)\n        if self.transform:\n            image = self.transform(image)\n\n        # print(type(label))\n        # print(type(image))\n        return image, label\n\n\n# %reload_ext kedro.ipython\n\n[11/08/24 22:03:27] INFO     Registered line magic '%reload_kedro'                                   __init__.py:58\n\n\n\n                    INFO     Registered line magic '%load_node'                                      __init__.py:60\n\n\n\n                    INFO     Resolved project path as: c:\\Users\\Admin\\Desktop\\onco-derm-ai.         __init__.py:175\n                             To set a different path, run '%reload_kedro &lt;project_root&gt;'                           \n\n\n\n                    INFO     Registering new custom resolver: 'km.random_name'                    mlflow_hook.py:62\n\n\n\n                    WARNING  No 'mlflow.yml' config file found in environment. Default            mlflow_hook.py:75\n                             configuration will be used. Use ``kedro mlflow init`` command in CLI                  \n                             to customize the configuration.                                                       \n\n\n\n                    INFO     The 'tracking_uri' key in mlflow.yml is relative            kedro_mlflow_config.py:260\n                             ('server.mlflow_(tracking|registry)_uri = mlruns'). It is                             \n                             converted to a valid uri:                                                             \n                             'file:///C:/Users/Admin/Desktop/onco-derm-ai/mlruns'                                  \n\n\n\n[11/08/24 22:03:28] INFO     Kedro is sending anonymous usage data with the sole purpose of improving plugin.py:233\n                             the product. No personal data or IP addresses are stored on our side. If              \n                             you want to opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK`              \n                             environment variables, or create a `.telemetry` file in the current                   \n                             working directory with the contents `consent: false`. Read more at                    \n                             https://docs.kedro.org/en/stable/configuration/telemetry.html                         \n\n\n\n[11/08/24 22:03:29] INFO     Kedro project onco-derm-ai                                             __init__.py:141\n\n\n\n                    INFO     Defined global variable 'context', 'session', 'catalog' and            __init__.py:142\n                             'pipelines'                                                                           \n\n\n\n                    INFO     Registered line magic 'run_viz'                                        __init__.py:148\n\n\n\n\nfrom kedro.io.data_catalog import DataCatalog\n\ncatalog = DataCatalog.from_config(\"../conf/base/catalog.yml\")\n\n\n# catalog\n\n\n\n\n\n{'train_dataset': 'kedro.io.memory_dataset.MemoryDataset()',\n 'train_intermediate': 'kedro.io.memory_dataset.MemoryDataset()',\n 'train_raw': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/data/01_raw/train.pkl'), \"\n              \"backend='pickle', protocol='file', load_args={}, save_args={}, \"\n              \"version=Version(load=None, save='2024-11-08T16.21.06.976Z'))\",\n 'val_raw': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/data/01_raw/val.pkl'), \"\n            \"backend='pickle', protocol='file', load_args={}, save_args={}, \"\n            \"version=Version(load=None, save='2024-11-08T16.21.06.976Z'))\",\n 'test_raw': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/data/01_raw/test.pkl'), \"\n             \"backend='pickle', protocol='file', load_args={}, save_args={}, \"\n             \"version=Version(load=None, save='2024-11-08T16.21.06.976Z'))\",\n 'pre-processed_train_data': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/data/02_intermediate/pre-processed_train_data.pkl'), \"\n                             \"backend='pickle', protocol='file', load_args={}, \"\n                             'save_args={}, version=Version(load=None, '\n                             \"save='2024-11-08T16.21.06.976Z'))\",\n 'image_classification_model': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/models/image_classification_model.pkl'), \"\n                               \"backend='pickle', protocol='file', \"\n                               'load_args={}, save_args={}, '\n                               'version=Version(load=None, '\n                               \"save='2024-11-08T16.21.06.976Z'))\",\n 'model_finetuned': \"kedro_datasets.pickle.pickle_dataset.PickleDataset(filepath=PurePosixPath('C:/Users/Admin/Desktop/onco-derm-ai/models/model_fintuned.pkl'), \"\n                    \"backend='pickle', protocol='file', load_args={}, \"\n                    'save_args={}, version=Version(load=None, '\n                    \"save='2024-11-08T16.21.06.976Z'))\",\n 'parameters': \"kedro.io.memory_dataset.MemoryDataset(data='&lt;dict&gt;')\",\n 'params:model_name': \"kedro.io.memory_dataset.MemoryDataset(data='&lt;str&gt;')\",\n 'params:num_epochs': \"kedro.io.memory_dataset.MemoryDataset(data='&lt;int&gt;')\"}\n\n\n\n\ntrain_data = catalog.load(\"pre-processed_train_data\")\n\n[11/08/24 22:03:40] INFO     Loading data from pre-processed_train_data (PickleDataset)...      data_catalog.py:539\n\n\n\n\n# train_data[\"image\"][0]\n\n\ntransform = transforms.Compose(\n    [\n        transforms.Resize((224, 224)),  # Resize to 224x224\n        # transforms.ToTensor(),             # Convert to tensor\n        transforms.Normalize(\n            mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n        ),  # Normalize\n    ]\n)\n\n# Load your dataset\ntrain_dataset = DermaMNISTDataset(train_data, transform=transform)\ntrain_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n\n# Initialize ResNet-18 model\nmodel = models.resnet18(pretrained=True)\nnum_classes = 7\nmodel.fc = nn.Linear(\n    model.fc.in_features, num_classes\n)  # Adjust final layer for DermaMNIST classes\n\n# Set up loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=0.001)\n\n# Training loop\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nmodel = model.to(device)\n\nnum_epochs = 10  # Adjust as needed\n\n# train_loader\n\n[11/08/24 22:03:45] WARNING  c:\\Users\\Admin\\miniconda3\\envs\\MlOps\\lib\\site-packages\\torchvision\\mod warnings.py:109\n                             els\\_utils.py:208: UserWarning: The parameter 'pretrained' is                         \n                             deprecated since 0.13 and may be removed in the future, please use                    \n                             'weights' instead.                                                                    \n                               warnings.warn(                                                                      \n                                                                                                                   \n\n\n\n                    WARNING  c:\\Users\\Admin\\miniconda3\\envs\\MlOps\\lib\\site-packages\\torchvision\\mod warnings.py:109\n                             els\\_utils.py:223: UserWarning: Arguments other than a weight enum or                 \n                             `None` for 'weights' are deprecated since 0.13 and may be removed in                  \n                             the future. The current behavior is equivalent to passing                             \n                             `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use                            \n                             `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.                \n                               warnings.warn(msg)                                                                  \n                                                                                                                   \n\n\n\n\nimages = \"\"\nlabels = \"\"\noutputs = \"\"\nlost = \"\"\n\n\nfor epoch in range(num_epochs):\n    model.train()\n    running_loss = 0.0\n    for i, lbs in train_loader:\n        # print(type(images))\n        images, labels = i.to(device), lbs.to(device)\n\n        # Forward pass\n        outputs = model(images)\n        # print(labels)\n        labels_output = labels.squeeze().long()\n        loss = criterion(outputs, labels_output)\n\n        # Backward and optimize\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    # print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")\n    # Save the model checkpoint\ntorch.save(model.state_dict(), \"resnet18_dermamnist.pth\")\n# print(\"Pre-training complete.\")\n\nEpoch [1/10], Loss: 0.8958\n\n\n╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮\n│ in &lt;module&gt;:19                                                                                   │\n│                                                                                                  │\n│   16 │   │   loss.backward()                                                                     │\n│   17 │   │   optimizer.step()                                                                    │\n│   18 │   │                                                                                       │\n│ ❱ 19 │   │   running_loss += loss.item()                                                         │\n│   20 │                                                                                           │\n│   21 │   print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}\")    │\n│   22 │   # Save the model checkpoint                                                             │\n╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\nKeyboardInterrupt"
  },
  {
    "objectID": "docs/index.html",
    "href": "docs/index.html",
    "title": "OncoDerm AI",
    "section": "",
    "text": "Project Proposal\n\nExecutive Summary\nWe propose developing a machine learning-based skin cancer screening system utilizing dermatoscopic images. The system will assist medical professionals in preliminary skin lesion assessment while incorporating robust MLOps practices and responsible AI principles.\n\n\nProblem Statement\nSkin cancer diagnosis requires expert dermatological knowledge and careful image analysis. While machine learning can assist in this process, deploying such systems in clinical settings requires careful consideration of reliability, explainability, and operational excellence.\n\n\nDataset\n\nSource: DermaMNIST (based on HAM10000)\nClasses: 7 distinct skin lesion categories:\n\nActinic keratoses and intraepithelial carcinoma (akiec)\nBasal cell carcinoma (bcc)\nBenign keratosis-like lesions (bkl)\nDermatofibroma (df)\nMelanoma (mel)\nMelanocytic nevi (nv)\nVascular lesions (vasc)\n\nCharacteristics:\n\n28x28 pixel dermatoscopic images\n10,015 training images\n1,268 validation images\n2,239 test images\n\nData Split: Predefined splits provided by MedMNIST\n\n\n\nTechnical Architecture\n\n1. Model Development\n\nBase Architecture:\n\nResNet-18 or MobileNetV2 (modified for 28x28 input)\nConsideration for lightweight models due to smaller input size\n\nTraining Pipeline:\n\nData augmentation (rotation, flipping, color jittering)\nTransfer learning with ImageNet weights\nFine-tuning strategies for small image sizes\nCross-validation for robust performance estimation\n\n\n\n\n2. MLOps Infrastructure\n\nData Pipeline:\n\nData ingestion and preprocessing\nData versioning\nData quality checks\n\nExperiment Tracking:\n\nMLflow for model versioning and tracking\nHyperparameter optimization\nModel performance visualization\n\nCI/CD Pipeline:\n\nAutomated testing (unit, integration, model performance)\nAutomated model deployment\nAutomated documentation generation\n\nMonitoring:\n\nModel performance metrics\nData drift detection\nAutomatic retraining triggers\n\n\n\n\n3. Production Features\n\nModel Robustness & Reliability\n\nExplainability:\nConfidence Calibration:\nAdversarial Robustness:\nOut-of-Distribution Detection:\n\n\n\nClinical Integration\n\nInteractive Dashboard:\n\nReal-time inference results\nConfidence scores and explanations\nImage preprocessing and quality checks\nResolution handling and upscaling options\n\nConformal Predictions:\n\nSet-valued predictions with guaranteed coverage\nCalibrated confidence scores\n\n\n\n\nData Privacy & Compliance\n\nRight to Erasure:\n\nAutomated removal pipeline\n\n\n\n\n\n\nEvaluation Metrics\n\nTechnical Metrics\n\nModel accuracy\nPrecision, recall, F1-score per class\nInference latency\nData drift metrics\n\n\n\nClinical Metrics\n\nFalse positive/negative rates\nCalibration error\nOOD detection accuracy\nExplanation quality (user feedback)\n\n\n\n\nChallenges & Risks\n\nTechnical Risks:\n\nLimited resolution impact on performance\nModel bias\nSystem scalability\nIntegration challenges\n\nClinical Risks:\n\nOver-reliance on system\nMisinterpretation of results\nEdge case handling\nResolution limitations affecting diagnosis\n\n\n\n\nMitigation Strategies\n\nClear Disclaimer: System is for screening assistance only\nResolution Warning: Clear indication of image resolution limitations\nComprehensive Documentation: Usage guidelines and limitations\nRegular Updates: Continuous model improvement\nUser Training: Proper system usage and interpretation\n\n\n\nFuture Enhancements\n\nVQA chatbot for assisting medical professionals\nExtension to other dermoscopic datasets"
  },
  {
    "objectID": "notebooks/DermaMnist.html",
    "href": "notebooks/DermaMnist.html",
    "title": "Importing data from medmnist",
    "section": "",
    "text": "To configure the data catalog, run the below cells. These cells will download the data from the medmnist dataset and save it in the data directory as a dataframe encapsuled in a pickle file.\n\n# !pip install medmnist\n\n\nfrom medmnist import DermaMNIST\n\n\ndata_train = DermaMNIST(split=\"train\", download=True, root=\"../data/01_raw/\")\n\nDownloading https://zenodo.org/records/10519652/files/dermamnist.npz?download=1 to ../data/01_raw/dermamnist.npz\n\n\n100%|██████████| 19.7M/19.7M [00:52&lt;00:00, 379kB/s] \n\n\n\nimport numpy as np\n\nds = np.load(\"../data/01_raw/dermamnist.npz\")\n\n\ntrain_images = ds[\"train_images\"]\ntrain_labels = ds[\"train_labels\"]\nval_images = ds[\"val_images\"]\nval_labels = ds[\"val_labels\"]\ntest_images = ds[\"test_images\"]\ntest_labels = ds[\"test_labels\"]\n\n\ntrain_len = len(train_images)\nval_len = len(val_images)\ntest_len = len(test_images)\n\n\n# generate ids array\ntrain_ids = [f\"train_{i}\" for i in range(train_len)]\nval_ids = [f\"val_{i}\" for i in range(val_len)]\ntest_ids = [f\"test_{i}\" for i in range(test_len)]\n\n\ntrain_images = list(train_images)\nval_images = list(val_images)\ntest_images = list(test_images)\n\n\ntrain_labels = list(train_labels)\nval_labels = list(val_labels)\ntest_labels = list(test_labels)\n\n\n# construct a df for each of the splits\nimport pandas as pd\n\ntrain_df = pd.DataFrame(\n    {\n        \"id\": train_ids,\n        \"image\": train_images,\n        \"label\": train_labels,\n    }\n)\ntest_df = pd.DataFrame(\n    {\n        \"id\": test_ids,\n        \"image\": test_images,\n        \"label\": test_labels,\n    }\n)\nval_df = pd.DataFrame(\n    {\n        \"id\": val_ids,\n        \"image\": val_images,\n        \"label\": val_labels,\n    }\n)\n\n\ntrain_df.to_pickle(\"../data/01_raw/train.pkl\")\ntest_df.to_pickle(\"../data/01_raw/test.pkl\")\nval_df.to_pickle(\"../data/01_raw/val.pkl\")\n\n\ntrain_df_loaded = pd.read_pickle(\"../data/01_raw/train.pkl\")\n\n\ntrain_df_loaded[\"image\"].iloc[0].shape\n\n(28, 28, 3)\n\n\n\ndef normalizing_images(data: pd.DataFrame) -&gt; pd.DataFrame:\n    data[\"image\"] = data[\"image\"].apply(lambda x: x / 255.0)\n    return data\n\n\ntrain_df_loaded_new = normalizing_images(train_df_loaded)\ntrain_df_loaded_new\n\n\n\n\n\n\n\n\nid\nimage\nlabel\n\n\n\n\n0\ntrain_0\n[[[0.002429834678969627, 0.001707035755478662,...\n[0]\n\n\n1\ntrain_1\n[[[0.003537101114955786, 0.001707035755478662,...\n[5]\n\n\n2\ntrain_2\n[[[0.003521722414455979, 0.002399077277970012,...\n[5]\n\n\n3\ntrain_3\n[[[0.003506343713956171, 0.0019530949634755863...\n[5]\n\n\n4\ntrain_4\n[[[0.0033217993079584776, 0.002891195693963860...\n[4]\n\n\n...\n...\n...\n...\n\n\n7002\ntrain_7002\n[[[0.0030911188004613607, 0.001953094963475586...\n[5]\n\n\n7003\ntrain_7003\n[[[0.003506343713956171, 0.0018762014609765476...\n[5]\n\n\n7004\ntrain_7004\n[[[0.00030757400999615535, 0.00027681660899653...\n[2]\n\n\n7005\ntrain_7005\n[[[0.002629757785467128, 0.002168396770472895,...\n[5]\n\n\n7006\ntrain_7006\n[[[0.003675509419454056, 0.002399077277970012,...\n[5]\n\n\n\n\n7007 rows × 3 columns\n\n\n\n\nfrom torchvision import transforms\n\n\ndef tensoring_resizing(data: pd.DataFrame) -&gt; pd.DataFrame:\n    transform = transforms.Compose(\n        [transforms.ToPILImage(), transforms.Resize((28, 28)), transforms.ToTensor()]\n    )\n\n    data[\"image\"] = data[\"image\"].apply(lambda x: transform(x).permute(1, 2, 0).numpy())\n    return data\n\n\ntrain_df_loaded_new = tensoring_resizing(train_df_loaded_new)\ntrain_df_loaded_new[\"image\"].iloc[0].shape\n\n(28, 28, 3)\n\n\n\n%load_ext kedro.ipython\n\n[11/05/24 23:08:04] INFO     Registered line magic '%reload_kedro'                                   __init__.py:61\n\n\n\n                    INFO     Registered line magic '%load_node'                                      __init__.py:63\n\n\n\n                    INFO     Resolved project path as: /home/saimadhavang/sem7/mlpe/onco-derm-ai.   __init__.py:178\n                             To set a different path, run '%reload_kedro &lt;project_root&gt;'                           \n\n\n\n                    INFO     Kedro is sending anonymous usage data with the sole purpose of improving plugin.py:233\n                             the product. No personal data or IP addresses are stored on our side. If              \n                             you want to opt out, set the `KEDRO_DISABLE_TELEMETRY` or `DO_NOT_TRACK`              \n                             environment variables, or create a `.telemetry` file in the current                   \n                             working directory with the contents `consent: false`. Read more at                    \n                             https://docs.kedro.org/en/stable/configuration/telemetry.html                         \n\n\n\n[11/05/24 23:08:05] INFO     Kedro project onco-derm-ai                                             __init__.py:144\n\n\n\n                    INFO     Defined global variable 'context', 'session', 'catalog' and            __init__.py:145\n                             'pipelines'                                                                           \n\n\n\n[11/05/24 23:08:07] INFO     Registered line magic 'run_viz'                                        __init__.py:151\n\n\n\n\nfrom kedro.io.data_catalog import DataCatalog\n\ncatalog = DataCatalog.from_config(\"../conf/base/catalog.yml\")\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[2], line 3\n      1 from kedro.io.data_catalog import DataCatalog\n----&gt; 3 catalog = DataCatalog.from_config(\"../conf/base/catalog.yml\")\n\nFile c:\\Users\\Admin\\miniconda3\\envs\\MlOps\\lib\\site-packages\\kedro\\io\\data_catalog.py:314, in DataCatalog.from_config(cls, catalog, credentials, load_versions, save_version)\n    311 load_versions = copy.deepcopy(load_versions) or {}\n    312 user_default = {}\n--&gt; 314 for ds_name, ds_config in catalog.items():\n    315     if not isinstance(ds_config, dict):\n    316         raise DatasetError(\n    317             f\"Catalog entry '{ds_name}' is not a valid dataset configuration. \"\n    318             \"\\nHint: If this catalog entry is intended for variable interpolation, \"\n    319             \"make sure that the key is preceded by an underscore.\"\n    320         )\n\nAttributeError: 'str' object has no attribute 'items'\n\n\n\n\ncatalog.save(\"train_raw\", train_df)\ncatalog.save(\"test_raw\", test_df)\ncatalog.save(\"val_raw\", val_df)\n\n[11/05/24 23:13:11] INFO     Saving data to train_raw (PickleDataset)...                        data_catalog.py:431\n\n\n\n                    INFO     Saving data to test_raw (PickleDataset)...                         data_catalog.py:431\n\n\n\n                    INFO     Saving data to val_raw (PickleDataset)...                          data_catalog.py:431\n\n\n\n\ndf = catalog.load(\"train_raw\")\n\n[11/05/24 23:13:47] INFO     Loading data from train_raw (PickleDataset)...                     data_catalog.py:389\n\n\n\n\ndf[\"image\"][0].shape\n\n\n\n\n\n(28, 28, 3)\n\n\n\n\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n\ndevice\n\ndevice(type='cuda')"
  },
  {
    "objectID": "reference/index.html",
    "href": "reference/index.html",
    "title": "API Reference",
    "section": "",
    "text": "Functions in the data_preprocessing pipeline\n\n\n\nnormalizing_images\nNormalize the pixel values of images in the given DataFrame.\n\n\ntensoring_resizing\nApplies a series of transformations to the ‘image’ column of a pandas DataFrame."
  },
  {
    "objectID": "reference/index.html#data_preprocessing",
    "href": "reference/index.html#data_preprocessing",
    "title": "API Reference",
    "section": "",
    "text": "Functions in the data_preprocessing pipeline\n\n\n\nnormalizing_images\nNormalize the pixel values of images in the given DataFrame.\n\n\ntensoring_resizing\nApplies a series of transformations to the ‘image’ column of a pandas DataFrame."
  },
  {
    "objectID": "reference/tensoring_resizing.html",
    "href": "reference/tensoring_resizing.html",
    "title": "tensoring_resizing",
    "section": "",
    "text": "tensoring_resizing(data)\nApplies a series of transformations to the ‘image’ column of a pandas DataFrame.\nThe transformations include converting images to PIL format, resizing them to 28x28 pixels, and converting them to tensors. The transformed images are then permuted and converted back to numpy arrays.\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\nDefault\n\n\n\n\ndata\npd.DataFrame\nA pandas DataFrame containing an ‘image’ column with image data.\nrequired\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nName\nType\nDescription\n\n\n\n\n\npd.DataFrame\nThe input DataFrame with the ‘image’ column transformed."
  },
  {
    "objectID": "reference/tensoring_resizing.html#parameters",
    "href": "reference/tensoring_resizing.html#parameters",
    "title": "tensoring_resizing",
    "section": "",
    "text": "Name\nType\nDescription\nDefault\n\n\n\n\ndata\npd.DataFrame\nA pandas DataFrame containing an ‘image’ column with image data.\nrequired"
  },
  {
    "objectID": "reference/tensoring_resizing.html#returns",
    "href": "reference/tensoring_resizing.html#returns",
    "title": "tensoring_resizing",
    "section": "",
    "text": "Name\nType\nDescription\n\n\n\n\n\npd.DataFrame\nThe input DataFrame with the ‘image’ column transformed."
  }
]